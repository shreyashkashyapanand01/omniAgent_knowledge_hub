# Omni-Agent Knowledge Hub

**Omni-Agent Knowledge Hub** is a unified AI platform that integrates advanced Generative AI concepts into a single, modular application. It combines Retrieval-Augmented Generation (RAG), autonomous agents, multi-modal ingestion, and code generation to create a powerful research and development assistant.

## ğŸš€ Features

*   **ğŸ§  Intelligent Routing (LangGraph)**: An autonomous agent that dynamically routes user queries to either a specialized Vector Store (for internal knowledge) or Wikipedia (for general knowledge).
*   **ğŸ“š Multi-Modal Ingestion**:
    *   **PDF RAG**: Upload and index PDF documents for deep semantic search.
    *   **YouTube & Web Summarization**: Ingest YouTube videos or website URLs, generate concise summaries, and store the content for future querying.
*   **ğŸ’¾ Vector Memory (AstraDB)**: Uses DataStax AstraDB as a serverless vector store to maintain long-term knowledge.
*   **ğŸ’» Dedicated Code Assistant**: A specialized mode powered by **CodeLlama** (via Ollama) to assist with programming tasks, debugging, and script generation.
*   **ğŸ¨ Modern UI**: A clean, glassmorphism-inspired interface built with vanilla HTML/CSS/JS for a lightweight and responsive experience.

## ğŸ› ï¸ Tech Stack

*   **Backend**: FastAPI, Python
*   **Frontend**: HTML5, CSS3, JavaScript
*   **AI/ML Frameworks**: LangChain, LangGraph
*   **Database**: DataStax AstraDB (Vector Store)
*   **LLMs**:
    *   **Groq** (Llama 3) for fast inference and routing.
    *   **Ollama** (CodeLlama) for local code generation.
    *   **HuggingFace** for embeddings.

## ğŸ“‹ Prerequisites

Ensure you have the following installed/configured:

*   **Python 3.9+**
*   **Ollama** (running locally with `codellama` model pulled)
*   **API Keys**:
    *   Groq API Key
    *   AstraDB Token & Endpoint
    *   HuggingFace Token

## âš™ï¸ Installation

1.  **Clone the repository** (if applicable) or navigate to the project folder:
    ```bash
    cd omniAgent_knowledge_hub
    ```

2.  **Create a virtual environment** (recommended):
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows: venv\Scripts\activate
    ```

3.  **Install dependencies**:
    ```bash
    pip install -r requirements.txt
    ```

4.  **Configure Environment Variables**:
    Create a `.env` file in the root directory and add your credentials:
    ```env
    GROQ_API_KEY="your_groq_key"
    ASTRA_DB_APPLICATION_TOKEN="your_astra_token"
    ASTRA_DB_API_ENDPOINT="your_astra_endpoint"
    HF_TOKEN="your_hf_token"
    OLLAMA_BASE_URL="http://localhost:11434"
    ```

## ğŸš€ Usage

1.  **Start the Backend Server**:
    ```bash
    uvicorn backend.main:app --reload
    ```
    The API will run at `http://localhost:8000`.

2.  **Launch the Frontend**:
    Open `frontend/index.html` in your preferred web browser.

3.  **Interact**:
    *   **General Knowledge**: Ask questions. The agent will decide whether to use your uploaded documents or Wikipedia.
    *   **Ingest**: Use the sidebar to upload PDFs or paste YouTube URLs.
    *   **Code Mode**: Switch to "Code Assistant" to generate code snippets.

## ğŸ“‚ Project Structure

```
omniAgent_knowledge_hub/
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ main.py          # FastAPI application & endpoints
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html       # Main UI
â”‚   â”œâ”€â”€ style.css        # Styling
â”‚   â””â”€â”€ script.js        # Frontend logic & API calls
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ agent.py         # LangGraph agent & routing logic
â”‚   â”œâ”€â”€ ingestion.py     # PDF/URL processing & summarization
â”‚   â”œâ”€â”€ vector_store.py  # AstraDB connection & embedding logic
â”‚   â””â”€â”€ code_assistant.py# Ollama integration for code gen
â”œâ”€â”€ .env                 # API keys (not shared)
â””â”€â”€ requirements.txt     # Python dependencies
```

---
*Built as a demonstration of Agentic AI capabilities.*
